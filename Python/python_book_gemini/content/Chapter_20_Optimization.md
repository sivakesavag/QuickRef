# Chapter 20: Performance & Optimization

**Target MCQs**: 50-60
**Current Batch**: 1-30
**Topics Covered**: `timeit` module, `cProfile` and `profile`, `pstats`, Memory profiling (`tracemalloc`, `sys.getsizeof`), Generators vs Lists for memory, Slot usage (`__slots__`), String concatenation (`join` vs `+`), Set lookups vs List lookups, Memoization (`lru_cache`).

---

**Q20.1: Basic - [Timeit Module]**

The standard library module for measuring execution time of small code snippets is:

A) `time`
B) `timeit`
C) `profile`
D) `stopwatch`

**Answer: B**

**Explanation:**
`timeit` avoids common pitfalls (like system background load) by running code multiple times and taking the best average.

---

**Q20.2: Intermediate - [String Concatenation]**

Which method is strictly more memory/CPU efficient for joining many strings in a loop?

A) `s = ""; for x in list: s += x`
B) `"".join(list_of_strings)`
C) `s = f"{s}{x}"`
D) `s = s + x`

**Answer: B**

**Explanation:**
`join` pre-calculates the final size and allocates memory once. Repeated `+=` creates a new string object in every iteration (quadratic behavior in some implementations, though newer Pythons optimize this slightly, `join` is still best practice).

---

**Q20.3: Advanced - [Slots]**

Using `__slots__` in a class definition:

A) Makes the class faster to instantiate and saves memory by suppressing `__dict__`.
B) Allows dynamic attribute addition.
C) Slows down the class.
D) Is only for abstract base classes.

**Answer: A**

**Explanation:**
By restricting valid attributes to a fixed set, Python uses a compact array structure instead of a dynamic dictionary for instances.

---

**Q20.4: Basic - [CProfile]**

`cProfile` is:

A) A C extension module for deterministic profiling of Python programs.
B) A pure Python profiler (slow).
C) A concurrency tool.
D) A linter.

**Answer: A**

**Explanation:**
Preferred over `profile` (pure Python) because it introduces much less overhead.

---

**Q20.5: Intermediate - [List Search Complexity]**

Checking `x in my_list` has a time complexity of:

A) O(1)
B) O(log N)
C) O(N)
D) O(N^2)

**Answer: C**

**Explanation:**
Lists are sequential; Python must scan elements one by one.

---

**Q20.6: Advanced - [Set Search Complexity]**

Checking `x in my_set` has an average time complexity of:

A) O(1)
B) O(log N)
C) O(N)
D) O(N^2)

**Answer: A**

**Explanation:**
Sets are implemented as hash tables, allowing constant-time lookups on average.

---

**Q20.7: Basic - [Sys Getsizeof]**

`sys.getsizeof(obj)` returns:

A) Size of object in bytes.
B) Size in bits.
C) Length of list.
D) Memory address.

**Answer: A**

**Explanation:**
Returns the internal memory consumption of the object structure (excluding referenced objects usually, unless deep traversal is done).

---

**Q20.8: Intermediate - [Generators Memory]**

Why use a generator `(x for x in range(1M))` over a list `[x for x in range(1M)]`?

A) Generators are always faster.
B) Generators consume significantly less memory (lazy evaluation).
C) Lists are deprecated.
D) Generators can be indexed.

**Answer: B**

**Explanation:**
A list stores 1 million integers concurrently. A generator produces one at a time, requiring only constant memory.

---

**Q20.9: Advanced - [Pstats Module]**

The `pstats` module is used to:

A) Collect statistics from the OS.
B) Read and analyze the binary output files generated by `cProfile`.
C) Graph performance.
D) Statistically predict bugs.

**Answer: B**

**Explanation:**
Allows sorting (e.g., by cumulative time, call count) and filtering profiling data.

---

**Q20.10: Expert - [LRU Cache Overhead]**

Does `@functools.lru_cache` always speed up code?

A) Yes.
B) No, it adds dictionary lookup overhead. It only speeds up if the function is computationally expensive and input arguments repeat.
C) No, it slows down everything by 50%.
D) Only for I/O bound tasks.

**Answer: B**

**Explanation:**
If the function is trivial (e.g., `return x+1`) and called with unique args every time, the cache management cost outweighs any benefit.

---

**Q20.11: Basic - [Premature Optimization]**

"Premature optimization is the root of all evil" (Knuth) implies:

A) You should never optimize.
B) You should write correct, readable code first, and optimize only identified bottlenecks.
C) You should optimize before writing code.
D) Optimization is illegal.

**Answer: B**

**Explanation:**
Optimization often reduces readability. It should be applied strictly where profiling proves it's needed.

---

**Q20.12: Intermediate - [Local vs Global]**

Accessing local variables inside a function is:

A) Slower than global variables.
B) Faster than global variables.
C) Same speed.
D) Impossible.

**Answer: B**

**Explanation:**
Locals are stored in a fixed-size array (FAST calling convention), whereas globals require a dictionary lookup.

---

**Q20.13: Advanced - [TraceMalloc]**

`tracemalloc` module helps to:

A) Trace memory allocations to identify leaks and peak usage.
B) Trace CPU usage.
C) Trace network calls.
D) Trace malware.

**Answer: A**

**Explanation:**
Can record stack traces where memory blocks were allocated.

---

**Q20.14: Basic - [Big O Notation]**

O(N^2) represents:

A) Linear time.
B) Quadratic time (e.g., nested loops).
C) Constant time.
D) Logarithmic time.

**Answer: B**

**Explanation:**
Performance degrades heavily as input size `N` grows.

---

**Q20.15: Intermediate - [In Place Sort]**

`list.sort()` vs `sorted(list)`:

A) `list.sort()` is in-place (updates original, returns None), saving memory copy.
B) `sorted()` is in-place.
C) No difference.
D) `list.sort()` is slower.

**Answer: A**

**Explanation:**
If you don't need the original unsorted list, `list.sort()` is slightly more efficient.

---

**Q20.16: Advanced - [Interning]**

Python "interns" (reuses) small integers (usually -5 to 256) and some strings. This means:

A) `a = 10; b = 10` might point to the same object in memory.
B) `a = 10; b = 10` are always potentially different objects.
C) Integers are mutable.
D) Memory usage is doubled.

**Answer: A**

**Explanation:**
Optimization to save memory for frequently used immutable objects.

---

**Q20.17: Expert - [Gil Impact CPU]**

For purely CPU-bound tasks (e.g., heavy math), multithreading in Python:

A) Speeds up execution linearly with cores.
B) Often degrades performance due to GIL context switching overhead (threads cannot run Python bytecode in parallel).
C) Has no effect.
D) Is best practice.

**Answer: B**

**Explanation:**
For CPU tasks, `multiprocessing` is required to bypass the GIL. Threading is useful for I/O bound tasks.

---

**Q20.18: Intermediate - [Deque vs List]**

`collections.deque` is faster than `list` for:

A) Indexing `d[500]`.
B) Appending/popping from the left (`popleft`).
C) Sorting.
D) Iterating.

**Answer: B**

**Explanation:**
`deque` (double-ended queue) has O(1) append/pop at both ends. Lists have O(N) for `pop(0)` (shifting elements). Indexing `deque` is O(N).

---

**Q20.19: Basic - [Membership Test]**

Which is faster? `x in {1, 2, 3}` or `x in [1, 2, 3]`?

A) The list.
B) The set.
C) Equal.
D) Depends on OS.

**Answer: B**

**Explanation:**
Set lookups are O(1) vs List O(N).

---

**Q20.20: Advanced - [Map vs ListComp]**

Functionally `map(f, L)` vs `[f(x) for x in L]`: `map` can be slightly faster when:

A) `f` is a built-in C function (like `str` or `len`).
B) `f` is a lambda.
C) Always.
D) Never.

**Answer: A**

**Explanation:**
`map` avoids the interpreter loop overhead to call the function if the function itself is in C. List comprehension executes the loop in bytecode.

---

**Q20.21: Expert - [PyPy]**

PyPy is:

A) A Python library for pie charts.
B) An alternative Python implementation using a JIT (Just-In-Time) compiler, often significantly faster than CPython.
C) A linter.
D) A debugger.

**Answer: B**

**Explanation:**
Compiles hot code paths to machine code at runtime.

---

**Q20.22: Intermediate - [Dot Operation Cost]**

In a tight loop, `obj.method()` is slower than having `m = obj.method` outside the loop and calling `m()` inside. Why?

A) `.` involves attribute lookup (dictionary search).
B) Caching is bad.
C) It isn't slower.
D) Function calls are slow.

**Answer: A**

**Explanation:**
Resolving the method name repeatedly adds overhead. Hoisting it out acts as a manual cache.

---

**Q20.23: Basic - [Import Overhead]**

Imports should generally be at the top of the file because:

A) It looks nice.
B) Importing inside a function loops repeated checks `sys.modules` every time code runs (though fast, it's non-zero).
C) Global imports allow the linter to work.
D) It is required by syntax.

**Answer: B**

**Explanation:**
Plus it makes dependencies clear. Local imports are only for resolving circular deps or optional features.

---

**Q20.24: Advanced - [Key vs Cmp]**

Using `key` function in sort is faster than the old `cmp` (compare) function because:

A) `key` is called once per element; `cmp` is called N*logN times (once per comparison).
B) `cmp` is C based.
C) `key` runs in parallel.
D) It is not faster.

**Answer: A**

**Explanation:**
The Schwartzian transform pattern: `key` transforms elements to manageable sort keys once.

---

**Q20.25: Intermediate - [Range vs Xrange]**

In Python 3, `range()` behaves like:

A) Python 2's `range()` (returns a list).
B) Python 2's `xrange()` (returns a lazy sequence object).
C) A tuple.
D) A generator.

**Answer: B**

**Explanation:**
Memory efficient. It is not exactly a generator (it can be iterated multiple times), but a lazy sequence.

---

**Q20.26: Expert - [GC Disable]**

`gc.disable()` is sometimes used to:

A) Prevent garbage collection pauses during critical performance sections.
B) Delete files.
C) Clear memory.
D) Turn off Python.

**Answer: A**

**Explanation:**
Manual memory management override. Can improve performance if thousands of short-lived objects are created/destroyed, but risky if not re-enabled.

---

**Q20.27: Basic - [Profiling]**

Profiling is the process of:

A) Guessing where the code is slow.
B) Measuring where the program spends its time and resources.
C) Writing tests.
D) Formatting code.

**Answer: B**

**Explanation:**
Data-driven optimization.

---

**Q20.28: Advanced - [Weakref]**

`weakref` allows referring to an object:

A) Without preventing it from being garbage collected.
B) With a weak password.
C) With low priority.
D) Across networks.

**Answer: A**

**Explanation:**
Useful for caches (like `WeakKeyDictionary`) to avoid memory leaks where the cache itself keeps objects alive indefinitely.

---

**Q20.29: Intermediate - [Sleep 0]**

`time.sleep(0)`:

A) Does nothing.
B) Yields the CPU slice to other threads/processes (effectively "reschedule").
C) Errors.
D) Sleeps for 0.1s.

**Answer: B**

**Explanation:**
Useful in tight loops to prevent starving other threads.

---

**Q20.30: Expert - [Dis Module]**

The `dis` module:

A) Disables code.
B) Disassembles Python functions into bytecode.
C) Displays graphics.
D) Distributes code.

**Answer: B**

**Explanation:**
Allows inspection of the underlying VM instructions, useful for understanding *why* one snippet is faster than another.

---

**Q20.31: Intermediate - [Generator Return]**

Generators save memory because:

A) They compress data.
B) They calculate values on-the-fly (lazy evaluation) and yield them one by one, rather than storing a full list in memory.
C) They use C pointers.
D) They are smaller objects.

**Answer: B**

**Explanation:**
Standard mechanism for handling large streams of data efficiently.

---

**Q20.32: Advanced - [Key Search List vs Set]**

Searching for a key in a `list` is O(N). Searching in a `dict` (or `set`) is O(1). This means:

A) Dict is always faster, even for 2 elements.
B) Dict is faster for large N, but has higher constant overhead (hashing). For very small N, list might be comparable or faster.
C) List is faster for large N.
D) They are the same.

**Answer: B**

**Explanation:**
For very small datasets (e.g., < 5 elements), the overhead of hashing might make linear scan competitive, but O(1) dominates as N grows.

---

**Q20.33: Basic - [Join vs Plus]**

`"".join(['a', 'b', 'c'])` is better than `'a' + 'b' + 'c'` inside a loop because:

A) It looks cleaner.
B) It avoids creating intermediate string objects for every concatenation step.
C) It sorts them.
D) It is Pythonic.

**Answer: B**

**Explanation:**
Concatenating strings is expensive because strings are immutable; a new object is created for every addition. `join` allocates the buffer once.

---

**Q20.34: Expert - [GC Generation]**

Python's Garbage Collector uses "generations" (0, 1, 2) to optimize collection. This hypothesis assumes:

A) Old objects die young.
B) Most new objects die young (are short-lived), so checking generation 0 frequently renders the most garbage.
C) All objects live forever.
D) RAM is infinite.

**Answer: B**

**Explanation:**
The "Generational Hypothesis". Young objects (gen 0) are scanned most frequently. Survivors are promoted to older generations (scanned less often).

---

**Q20.35: Intermediate - [Set Intersection Cost]**

`set_a.intersection(set_b)` complexity is roughly:

A) O(len(set_a) * len(set_b))
B) O(min(len(set_a), len(set_b))) (average case)
C) O(1)
D) O(N^2)

**Answer: B**

**Explanation:**
Python iterates over the smaller set and checks for membership in the larger set (O(1) lookup).

---

**Q20.36: Advanced - [LRU Cache Size]**

`@lru_cache(maxsize=None)`:

A) Caches nothing.
B) Caches identically to `maxsize=128`.
C) Allows the cache to grow without bound (potential memory leak if inputs vary infinitely).
D) Clears cache on every call.

**Answer: C**

**Explanation:**
Turning off the LRU eviction policy means the dictionary grows forever. Good for fixed input domains, dangerous for open-ended inputs.

---

**Q20.37: Basic - [Timeit Number]**

`timeit.timeit(..., number=1000)` means:

A) The code is run 1000 times.
B) The result is 1000 seconds.
C) The code is limited to 1000 bytes.
D) It runs until 1000 errors occur.

**Answer: A**

**Explanation:**
The `number` argument controls the loop count for averaging.

---

**Q20.38: Intermediate - [Sys Intern]**

`sys.intern(string)` is used to:

A) Delete the string.
B) Ensure that two strings with same content point to the same memory object (canonicalization), speeding up dictionary lookups.
C) Make a string private.
D) Compress the string.

**Answer: B**

**Explanation:**
Interned strings can be compared by pointer identity (`is`) rather than character-by-character (`==`), which is faster. Dicts allow faster lookups for interned keys.

---

**Q20.39: Advanced - [Profile vs CProfile]**

Why does `profile` exist if `cProfile` is better?

A) `profile` is written in Python, making it easier to extend or hack, despite the high overhead.
B) `profile` is faster.
C) `cProfile` is deprecated.
D) `profile` supports graphics.

**Answer: A**

**Explanation:**
Useful if you need a custom profiler logic that C extension doesn't support, but rarely used in production optimization unrelated to tool development.

---

**Q20.40: Expert - [Dict Memory]**

Compared to Python 3.5, `dict` in Python 3.6+ uses significantly less memory (compact dict). How?

A) By using arrays (indices) + a dense values array, rather than a sparse hash table array.
B) By compressing keys.
C) By removing collision resolution.
D) By storing on disk.

**Answer: A**

**Explanation:**
The "compact dict" implementation separates the hash table indices from the entry storage, reducing the footprint of sparse tables.

---

**Q20.41: Intermediate - [Any Generator]**

`any(very_expensive_check(x) for x in range(100))` is efficient because:

A) `any` stops (short-circuits) at the first True value, so `very_expensive_check` might not run for all 100 items.
B) It runs in parallel.
C) It caches results.
D) It is compiled to C.

**Answer: A**

**Explanation:**
Combined with a generator expression, this creates a lazy-evaluating, short-circuiting search.

---

**Q20.42: Basic - [Builtin Sum]**

`sum(list_of_numbers)` vs `reduce(lambda x,y: x+y, list_of_numbers)`:

A) `reduce` is faster.
B) `sum` is faster because it's a dedicated C implementation for numbers.
C) Equal.
D) `sum` is deprecated.

**Answer: B**

**Explanation:**
Built-ins specialized for common tasks are usually optimized in C.

---

**Q20.43: Advanced - [Refcount]**

`sys.getrefcount(obj)` returns:

A) The number of references to the object (including the one allocated for the argument to `getrefcount`).
B) The object size.
C) The memory address.
D) The type ID.

**Answer: A**

**Explanation:**
Generally count is 1 higher than you expect because passing it to the function creates a temporary reference.

---

**Q20.44: Expert - [Cycle Detector]**

Python's cycle detector (GC) is triggered:

A) On every allocation.
B) Based on a threshold of allocations minus deallocations.
C) Every second.
D) Never (manual only).

**Answer: B**

**Explanation:**
When `(allocs - deallocs) > threshold`, the GC runs a collection pass to find and break reference cycles.

---

**Q20.45: Intermediate - [Itertools Chain]**

Using `itertools.chain(list1, list2)` vs `list1 + list2`:

A) `chain` creates a new list.
B) `chain` yields elements from the first then the second without copying them into a new container (zero memory overhead).
C) `+` is faster.
D) `chain` is slow.

**Answer: B**

**Explanation:**
Avoids copying lists just to iterate over them sequentially.

---

**Q20.46: Basic - [Local Variable Speed]**

Reading a local variable is faster than a global because:

A) Locals are an array lookup (Opcode LOAD_FAST), Globals are dict lookup (Opcode LOAD_GLOBAL).
B) Locals are cached in CPU L1.
C) Globals are on disk.
D) No difference.

**Answer: A**

**Explanation:**
The Python VM optimizes access to local scope slots.

---

**Q20.47: Advanced - [Multiple Assignments]**

`a, b = b, a` swap operation is:

A) Atomic and fast (no temporary variable needed in source code).
B) Slower than using `temp`.
C) Unsafe.
D) Deprecated.

**Answer: A**

**Explanation:**
Python handles the stack rotation internally (`ROT_TWO`), making it idiomatic and efficient.

---

**Q20.48: Expert - [PyMalloc]**

Python (CPython) uses a custom memory allocator (pymalloc) for small objects (< 512 bytes) to:

A) Avoid the overhead of `malloc()` calls to the OS for every small object (fragmentation/speed).
B) Use GPU memory.
C) Encrypt memory.
D) Avoid GC.

**Answer: A**

**Explanation:**
Pymalloc manages "arenas" and "pools" to efficiently serve small memory requests.

---

**Q20.49: Intermediate - [Membership Set]**

To remove duplicates from a list `L` while preserving order (in modern Python):

A) `list(set(L))` (order lost).
B) `list(dict.fromkeys(L))` (order preserved in 3.7+).
C) `[x for x in L if x not in seen]` (slow).
D) `unique(L)`

**Answer: B**

**Explanation:**
Since dicts are ordered in modern Python, using keys is a fast way (O(N)) to deduplicate while keeping insertion order.

---

**Q20.50: Basic - [Context Manager Overhead]**

`with open(...)` is generally:

A) Slower than `f = open(); ... f.close()`.
B) Faster.
C) Negligible overhead compared to safety benefits (ensures closing).
D) Unsafe.

**Answer: C**

**Explanation:**
The overhead of the `with` block is microseconds; the safety of guaranteed resource cleanup is the priority.

---

---

## Review Notes (2026-02-06)

- No major content errors were identified in this review pass.
